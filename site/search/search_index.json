{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Via Foundry's Documentation!","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Platform Overview</li> <li>Pipeline Examples</li> <li>About</li> <li>How To Cite Us</li> </ul>"},{"location":"#user-guide","title":"User Guide","text":"<ul> <li>Quick Start Guide</li> <li>Project Guide</li> <li>Run Guide</li> <li>App Guide</li> <li>Profile Guide</li> <li>Frequently Asked Questions</li> </ul>"},{"location":"ViaFoundry/about/","title":"About","text":"<p>Via Foundry, formerly known as DolphinNext, is developed by the Bioinformatics Core at the University of Massachusetts Medical School (UMMS).</p> <p>This project is licensed under the GNU General Public License 3.0. The source code of DolphinNext is available at https://github.com/UMMS-Biocore/dolphinnext and you can reach our website at https://www.viafoundry.com.</p>"},{"location":"ViaFoundry/about/#how-to-cite-us","title":"How To Cite Us","text":"<p>If you use Via Foundry (formerly DolphinNext) in your research, please cite:</p> <p>Yukselen, O., Turkyilmaz, O., Ozturk, A.R. et al. DolphinNext: a distributed data processing platform for high throughput genomics. BMC Genomics 21, 310 (2020). https://doi.org/10.1186/s12864-020-6714-x</p>"},{"location":"ViaFoundry/app/","title":"App Guide","text":""},{"location":"ViaFoundry/app/#basics","title":"Basics","text":"<p>In the top navigation bar, you will find the \"App\" button. Clicking on this button allows you to access all the shared or public apps available. If you have a specific app in mind that you would like to create, we are here to assist you. Simply contact us at support@viascientific.com for guidance and support.</p> <p></p>"},{"location":"ViaFoundry/app/#-shiny-app-debrowser","title":"-   Shiny App - DEBrowser","text":"<p>DEBrowser is an R library which provides an easy way to perform and visualize DE (Differential Expression) analysis. This module takes count matrices as input and allows interactive exploration of the resulting data. You can find their documentation here.</p> <p></p>"},{"location":"ViaFoundry/app/#-r-studio-r-markdown","title":"-   R-Studio - R-Markdown","text":"<p>The R-Studio launcher facilitates interactive analysis of the data generated from a run. We have prepared a set of R-Markdown reports that provide access to your report in HTML or PDF format immediately after the run is completed.</p> <p>For instance, the code below performs differential expression analysis for each comparison listed in the compare file. It generates volcano and MA plots for differentially expressed genes in each comparison:</p> <p></p>"},{"location":"ViaFoundry/app/#-jupyter-notebook","title":"-   Jupyter Notebook","text":"<p>The Jupyter Notebook app, due to its interactive and flexible nature, it allows bioinformatics researchers to combine code, visualizations, and explanatory text in a single document. Bioinformaticians can write and execute code snippets in real-time, visualize data using various plotting libraries, and document their analyses step-by-step.</p> <p></p>"},{"location":"ViaFoundry/app/#-shiny-app-gsea-explorer","title":"-   Shiny App - GSEA Explorer","text":"<p>GSEA Explorer is an R library that offers a convenient method for conducting and visualizing Gene Set Enrichment Analysis (GSEA). GSEA aims to assess whether a specific gene set or pathway is enriched in gene expression data, indicating its potential biological significance in the studied condition. The GSEA Explorer application can be accessed after executing Foundry's complete RNA-sequencing pipeline or the standalone Differential Expression module. By leveraging GSEA Explorer, researchers can gain valuable insights into the functional implications of gene sets and pathways, aiding in the interpretation of RNA-seq results and facilitating a deeper understanding of biological mechanisms.</p> <p></p>"},{"location":"ViaFoundry/app/#-shiny-app-network-explorer","title":"-   Shiny App - Network Explorer","text":"<p>The Network Explorer allows bioinformaticians to explore and analyze these complex networks, helping them uncover hidden patterns, identify key players, and understand the underlying biological mechanisms. The Network Explorer application can be launched after running Foundry's full RNA-sequencing pipeline or the stand-alone Differential Expression module.</p> <p></p>"},{"location":"ViaFoundry/app/#support","title":"Support","text":"<p>For any questions or help, please reach out to support@viascientific.com with your name and question.</p>"},{"location":"ViaFoundry/cite/","title":"How To Cite Us","text":""},{"location":"ViaFoundry/cite/#how-to-cite-us","title":"How To Cite Us","text":"<p>If you use Via Foundry (formerly DolphinNext) in your research, please cite:</p> <p>Yukselen, O., Turkyilmaz, O., Ozturk, A.R. et al. DolphinNext: a distributed data processing platform for high throughput genomics. BMC Genomics 21, 310 (2020). https://doi.org/10.1186/s12864-020-6714-x</p>"},{"location":"ViaFoundry/faq/","title":"Frequently Asked Questions","text":""},{"location":"ViaFoundry/faq/#installation-guide","title":"Installation Guide","text":""},{"location":"ViaFoundry/faq/#how-can-i-install-singularity","title":"How can I install Singularity?","text":"<p>Follow this link to install Singularity (Version 3) for your pipelines. For your convenience, attached below are the commands needed to download the newest version in a Linux environment:</p> <pre><code>## Remove old version of Singularity\n# sudo rm -rf /usr/local/libexec/singularity /usr/local/var/singularity /usr/local/etc/singularity /usr/local/bin/singularity /usr/local/bin/run-singularity /usr/local/etc/bash_completion.d/singularity\n\n## Install Singularity Version 3\napt-get install -y build-essential libssl-dev uuid-dev libgpgme11-dev libseccomp-dev pkg-config squashfs-tools\nwget https://dl.google.com/go/go1.12.7.linux-amd64.tar.gz\ntar -C /usr/local -xzf go1.12.7.linux-amd64.tar.gz\nexport PATH=$PATH:/usr/local/go/bin\nexport VERSION=3.2.1 \nwget https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-${VERSION}.tar.gz\ntar -xzf singularity-${VERSION}.tar.gz\ncd singularity\n./mconfig &amp;&amp; make -C ./builddir \nsudo make -C ./builddir install\n</code></pre>"},{"location":"ViaFoundry/faq/#how-can-i-install-docker","title":"How can I install Docker?","text":"<p>Follow this link to install Docker for pipelines, or follow the commands below:</p> <pre><code>## Uninstall Old Versions of Docker\n# sudo apt-get remove docker docker-engine docker.io\n\n## Install Docker\nsudo apt install docker.io\n</code></pre>"},{"location":"ViaFoundry/faq/#how-can-i-install-java","title":"How can I install JAVA?","text":"<p>Installing Java v8+ for Nextflow:</p> <pre><code>apt-get install -y openjdk-8-jdk &amp;&amp; \napt-get install -y ant &amp;&amp; \napt-get clean;\n\n# Fix certificate issues\napt-get update &amp;&amp; \napt-get install ca-certificates-java &amp;&amp; \napt-get clean &amp;&amp; \nupdate-ca-certificates -f;\nexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/\n</code></pre>"},{"location":"ViaFoundry/faq/#how-can-i-install-nextflow","title":"How can I install Nextflow?","text":"<p>JAVA (v8+) should be installed before installing Nextflow. Once Java has been successfully installed, click this link to install Nextflow or use the commands below:</p> <pre><code>## To install to your ~/bin directory:\nmkdir ~/bin\ncd ~/bin\ncurl -fsSL get.nextflow.io | bash\n\n# Add Nextflow binary to your bin PATH or any accessible path in your environment:\nchmod 755 nextflow\nmv nextflow ~/bin/\n# OR system-wide installation:\n# sudo mv nextflow /usr/local/bin\n</code></pre>"},{"location":"ViaFoundry/faq/#connection-issues","title":"Connection Issues","text":""},{"location":"ViaFoundry/faq/#why-cant-i-validate-my-ssh-keys","title":"Why can't I validate my SSH Keys?","text":"<p>If you're having trouble validating your SSH keys, here are a few things to check:</p> <ol> <li> <p>Make sure you copy the entire key, including the initial part       (e.g. \"ssh-rsa\"). The key should span the entire file, like in       the following example:</p> <pre><code>  ssh-rsa\n  AA1AB3N4nX3a....................\n  ................................\n  ................................\n  ...............b9Rj @viafoundry\n</code></pre> </li> <li> <p>The SSH protocol requires specific permissions for files and       directories to establish secure connections. Please execute the       following commands to make sure your SSH-related files are       properly secured:</p> <pre><code>  chmod 700 ~/.ssh\n  chmod 600 ~/.ssh/authorized_keys\n</code></pre> </li> <li> <p>Ensure that your home directory is not writable by other       users. Setting the permissions of your home directory to 777 can       create security issues and block SSH connections. Instead, set the       permissions to more secure options such as 750, 755 or 754.</p> </li> </ol>"},{"location":"ViaFoundry/faq/#how-can-i-create-ssh-keys-in-my-computer","title":"How can I create SSH keys in my computer?","text":"<p>You can find your SSH key pairs on your local machine at their default location: <code>~/.ssh/id_rsa</code> for private and <code>~/.ssh/id_rsa.pub</code> for public key. If no keys exist there or you want to create new ones, then on the command line, enter:</p> <pre><code>ssh-keygen -t rsa\n</code></pre> <p>You will be prompted to supply a filename and a password. If you want to accept the default filename (and location) for your key pair, just press Enter without entering a filename. Your SSH keys will be generated using the default filename (<code>id_rsa</code> and <code>id_rsa.pub</code>), and they will be saved in the \"~/.ssh/\" directory in your machine.</p>"},{"location":"ViaFoundry/faq/#run-questions","title":"Run Questions","text":""},{"location":"ViaFoundry/faq/#i-cant-reach-my-files-in-the-file-window","title":"I can't reach my files in the file window","text":"<p>There might be a connection issue. Please check to make sure you've followed these steps:</p> <ol> <li> <p>The SSH protocol requires specific permissions for files and       directories to establish secure connections. Please execute the       following commands to make sure your SSH-related files are       properly secured:</p> <pre><code>  chmod 700 ~/.ssh\n  chmod 600 ~/.ssh/authorized_keys\n</code></pre> </li> <li> <p>Ensure that your home directory is not writable by other       users. Setting the permissions of your home directory to 777 can       create security issues and block SSH connections. Instead, set the       permissions to more secure options such as 750, 755 or 754.</p> </li> </ol>"},{"location":"ViaFoundry/faq/#error-run-directory-cannot-be-created","title":"Error: Run directory cannot be created","text":"<p>It's possible that there's an issue with your connection. Please check the Why can't I validate my SSH Keys section to ensure you've followed all the necessary steps.</p>"},{"location":"ViaFoundry/faq/#profile-questions","title":"Profile Questions","text":""},{"location":"ViaFoundry/faq/#how-should-i-configure-my-executor-settings","title":"How should I configure my executor settings?","text":"<p>In Via Foundry, there are four different sections to control executor settings: the first two are defined in Profile -  Run Environment, and the remaining two are adjusted in the Advanced tab of the run page. If you select an executor other than \"Local\" or \"Ignite\", Via Foundry prompts you to enter additional settings, such as the queue/partition, memory, CPU, and time.</p> <p>1. Executor of Nextflow (navigate to Profile -  Run   Environments):</p> <p>This setting controls how Via Foundry initiates Nextflow. Currently,     Via Foundry supports the Local, SGE, SLURM, and LSF executors to     initiate Nextflow. For the SGE, SLURM, and LSF executors, Via     Foundry only uses them to run Nextflow itself, so the time limit     should be long enough to execute all processes in the pipeline. For     local execution, Via Foundry limits the total amount of memory and     CPU that can be used, so these values should be close to the maximum     capacity of your computer.</p> <ul> <li>Suggested parameters for SGE/SLURM/LSF: long (queue) 8 (GB         Memory) 1 (CPU) 5000-8000 (min, Time)</li> <li>Suggested parameters for Local: 100 (GB Memory) 8 (CPU)</li> </ul> <p>2. Executor of Nextflow Jobs (navigate to Profile -  Run   Environments):</p> <p>This setting will be used as the default setting for submitted jobs     by Nextflow if you don't set any parameters in the Advanced     section of your run page.</p> <ul> <li>Suggested parameters for SGE/SLURM/LSF: short (queue) 20 (GB         Memory) 1 (CPU) 240 (min, Time)</li> <li>Suggested parameters for Local: 20 (GB Memory) 1 (CPU)</li> </ul> <p>3. Executor Settings for All Processes (in the advanced tab of run   page):</p> <p>These settings will overwrite those in Executor of Nextflow Jobs     and set default parameters for all Nextflow Jobs.</p> <ul> <li>Suggested parameters for SGE/SLURM/LSF: short (queue) 20 (GB         Memory) 1 (CPU) 240 (min, Time)</li> <li>Suggested parameters for Local: 20 (GB Memory) 1 (CPU)</li> </ul> <p>4. Executor Settings for Each Process (in the advanced tab of run   page):</p> <p>If a particular process requires different parameters than the     defaults (which are defined in the Executor Settings for All     Processes or Executor of Nextflow Jobs sections), you can     overwrite the general settings by clicking the checkbox of the     process that you want to change. This will only affect the settings     of the selected process and keep the original settings for the rest     of the processes.</p> <ul> <li>Suggested parameters for SGE/SLURM/LSF: long (queue) 20 (GB         Memory) 4 (CPU) 1000-5000 (min, Time)</li> <li>Suggested parameters for Local: 20 (GB Memory) 4 (CPU)</li> </ul> <p>Note:    If non-standard resources or settings are required for the executor,   then you can specify these parameters by using Other Options box.   For instance, to submit an SGE job with 3 CPU using parallel   environments, you can enter <code>-pe orte 3</code> (to use MPI for   distributed-memory machines) or <code>-pe smp 3</code> (to use OpenMP for   shared-memory machines) in the Other Options box, leaving the CPU   box empty.</p>"},{"location":"ViaFoundry/overview/","title":"Short Overview","text":""},{"location":"ViaFoundry/overview/#what-is-via-foundry","title":"What is Via Foundry?","text":"<p>Via Foundry is the web interface of an intuitive and powerful bioinformatics platform designed to simplify pipeline design, development and maintenance, enabling analysis and management of mass quantities of samples on High Performance Computing (HPC) environments, cloud services (AWS, Google Cloud etc.), or personal workstations. It automatically builds Nextflow pipelines by assembling components such as processes and modules, enabling seamless implementation of complex bioinformatics workflows. Moreover, we offer assistance for nf-core or customized nextflow pipelines, allowing easy integration of these pipelines directly from Github or Bitbucket repositories.</p>"},{"location":"ViaFoundry/overview/#benefits-of-via-foundrys-design","title":"Benefits of Via Foundry's Design","text":"<ul> <li>Build: Via Foundry's drag-and-drop interface allows for     effortless creation of new pipelines, without the need to write     commands from scratch. Existing processes/modules can be reused to     create new pipelines, which can then be exported as Nextflow files     or readily run within Via Foundry.</li> <li>Run: Pipelines can be executed in any host environment with     different executors, such as SGE, LSF, SLURM, Ignite, and more. Via     Foundry also seamlessly integrates with Amazon/Google Cloud,     allowing for easy creation of a cluster in the cloud, execution of     the pipeline, and transfer of results to a cloud storage service     (Amazon Storage, S3 or Google Storage, GS).</li> <li>Resume: Via Foundry's continuous checkpoint mechanism keeps     track of each step of the running pipeline, enabling partially     completed pipelines to be resumed at any stage, even after parameter     changes.</li> <li> <p>Analyze: Via Foundry's report section provides a concise summary of  each executed step, facilitating efficient data analysis. It also allows  for seamless exploration of reported files through interactive applications  like Shiny App, R-Studio (R-Markdown), Jupyter Notebook, or any other containerized app.</p> </li> <li> <p>Improve: Via Foundry's revisioning system keeps track of     pipeline and process versions, as well as their parameters. This     allows for easy editing, improvement, and customization of shared     pipelines according to your needs.</p> </li> <li>Share: Via Foundry allows for easy sharing of pipelines across     different platforms, with the ability to isolate pipeline-specific     dependencies in a container and easily replicate methods in other     environments (clusters, clouds etc.).</li> </ul>"},{"location":"ViaFoundry/overview/#what-is-nextflow","title":"What is Nextflow?","text":"<p>Nextflow is an incredibly potent and versatile framework. Based on the dataflow programming model, it is used for building parallelized, scalable and reproducible workflows using software containers, which provides an abstraction layer between the execution and the logic of the pipeline, which means that the same pipeline code can be executed on multiple platforms.</p>"},{"location":"ViaFoundry/overview/#who-is-via-foundry-for","title":"Who is Via Foundry for?","text":"<p>Via Foundry is designed for a wide variety of users, from bench biologists to expert bioinformaticians.</p> <p>Executing pipelines in Via Foundry requires no programming knowledge. We aim to provide comprehensive explanations to guide users before they execute their pipelines. After a run completes, we provide an overall execution summary of each step, gathering all of the samples in simple tables or interactive apps/plots for ultimate comparison.</p> <p>Building pipelines in Via Foundry requires basic scripting knowledge and familiarization with Nextflow to effectively use its operators. You don't need to learn all of the Nextflow syntax; instead, you can easily focus on the processes where basic input and output nodes are defined. The rest, such as creating and linking the channels, is handled by Via Foundry.</p>"},{"location":"ViaFoundry/overview/#why-not-just-write-a-nextflow-pipeline","title":"Why not just write a Nextflow pipeline?","text":"<p>In many cases, building a static Nextflow pipeline is sufficient for achieving our goals. However, it can be difficult to maintain process and module revisions using simple text editors. With the help of Via Foundry's user interface, you can easily track the evolution of each process and module by accessing their previous revisions. When upgrading existing pipelines, it's much easier to update each process because all of the process-related scripts are isolated in a process circle, and you don't need to deal with other parameters or channel operations that are defined in other parts of the Nextflow script. This modular structure gives us more flexibility and dynamism to create very complex pipelines with little effort.</p> <p>Furthermore, Via Foundry has a built-in form creator that dynamically updates the run page according to the parameters defined in the process. This tool becomes especially powerful when creating complex pipelines with hundreds of optional parameters. As seen in the example below, you can easily isolate process-related parameters in their specific windows.</p> <p></p> <p>Please feel free to reference this image, which outlines the features of Via Foundry and Nextflow, to better understand the ethos of Via Foundry.</p> <p></p>"},{"location":"ViaFoundry/overview/#public-pipelines","title":"Public Pipelines","text":"<p>Attached is a brief list of Via Foundry's current public pipelines, along with some important sub-modules, all of which are ready to execute in your environment.</p> <ul> <li> <p>RNA-Seq Pipelines (RSEM, HISAT, STAR, Salmon, Kallisto, FeatureCounts)</p> </li> <li> <p>ATAC-Seq Pipeline (MACS2)</p> </li> <li> <p>ChIP Seq Pipeline (MACS2)</p> </li> <li> <p>Single Cell Pipelines (10X Genomics, Indrop)</p> </li> <li> <p>piRNA Pipelines (piPipes ChIP-Seq, Degradome/RAGE/CAGE, smallRNA)</p> </li> <li> <p>Sub-Modules:</p> <ul> <li>Trimmer</li> <li>Adapter Removal</li> <li>Quality Filtering</li> <li>Common RNA Filtering</li> <li>ESAT</li> <li>FastQC,</li> <li>MultiQC</li> <li>RSeQC</li> <li>Picard</li> <li>IGV and UCSC genome browser file conversion</li> </ul> </li> </ul>"},{"location":"ViaFoundry/pipeline_example/","title":"Pipeline Examples","text":"<p>There are numerous publicly available pipelines and processes available on the Via Foundry website. Please note that this document only contains a small sampling of the pipelines Via Foundry offers. For the full list of pipelines and to explore each pipeline in detail, please visit the Via Foundry Pipeline page.</p> <p>Once you navigate to the Pipelines tab, simply click on the respective pipeline's box to access a comprehensive overview. This summary provides detailed information regarding the pipeline, such as its usage instructions and example output/report sections.</p> <p></p>"},{"location":"ViaFoundry/pipeline_example/#rna-seq-pipeline","title":"RNA-Seq Pipeline","text":"<p>The RNA-seq pipeline publicly available in Via Foundry includes several key steps for processing RNA-seq data:</p> <ol> <li>Quality Control: FastQC is used to generate quality control (QC)     outputs. Optional processes such as read quality filtering     (trimmomatic), read quality trimming (trimmomatic), and adapter     removal (cutadapt) are available.</li> <li>rRNA Filtering and Genome Alignment: Bowtie2, Bowtie, and STAR are     utilized for counting or filtering out and estimating the abundance     of both standard and predefined sets of genomic loci, such as rRNAs,     miRNAs, tRNAs, piRNAs, snoRNAs, and ERCC.</li> <li>Gene and Isoform Expression Estimation: RSEM is employed to align     RNA-seq reads to reference transcripts and estimate gene and isoform     expression levels.</li> <li>Genome Alignment: HISAT2, STAR, Kallisto or Salmon are employed to align     RNA-seq reads to the genome. Optional estimation of gene and isoform     expression levels can be performed using featureCounts and Salmon.</li> <li>Quality Metrics and Reports: If the user opts to perform genomic     alignments, the pipeline generates overall quality metrics,     including coverage and the number of mapped reads to different     genomic and transcriptomic regions. These reports rely on Picard's     CollectRNASeqMetrics program (Broad Institute, n.d.) and the RSeQC     program (Wang, Wang, and Li 2012).</li> <li>Visualization: Optional generation of Integrative Genomics Viewer     (IGV) and Genome Browser Files (TDF and Bigwig) is available.</li> <li>Quantification Matrix and Analysis: The RNA-seq pipeline provides a     quantification matrix that includes estimated counts and transcript     per million (TPM) values for each gene and annotated isoform. These     matrices serve as input for differential gene expression analysis     and can be directly uploaded to an embedded instance of DEBrowser     software for interactive exploration of the resulting data     (Kucukural et al. 2019).</li> </ol> <p>Presented here is the example report tab for the RNA-Seq Run. Each section within the report consists of its own set of files, allowing you to thoroughly investigate and visualize the data within each respective section.</p> <p></p> <p>Below is a screenshot showcasing the interactive analysis of differential expression analysis using the Shiny app called DEbrowser.</p> <p></p>"},{"location":"ViaFoundry/pipeline_example/#atac-seq-and-chip-seq-pipelines","title":"ATAC-Seq and ChIP-Seq pipelines","text":"<p>Via Foundry offers comprehensive pipelines for the processing of ChIP-Seq and ATAC-Seq data, which are widely used in genomic research. Although these pipelines share many common processes, they exhibit specific differences at certain stages. Moreover, they rely on identical data preparation steps employed in the RNA-Seq pipeline, including read filtering, read quality reporting, and alignment to desired genomic locations.</p> <p>The key steps involved in the ChIP-Seq and ATAC-Seq pipelines are as follows:</p> <ol> <li>Quality Control: The pipelines utilize FastQC to assess the quality     of the sequencing reads and generate quality control outputs.     Additionally, optional processes such as read quality filtering     (trimmomatic), read quality trimming (trimmomatic), and adapter     removal (cutadapt) can be employed to further refine the data.</li> <li>Counting and Filtering: To estimate the abundance of both standard     and predefined sets of genomic loci (e.g., rRNAs, miRNAs, tRNAs,     piRNAs, snoRNAs, ERCC), the pipelines employ tools like     Bowtie2/Bowtie/STAR. These tools facilitate read counting or     filtering to obtain valuable insights into the genomic regions of     interest.</li> <li>Read Alignment: The short-read aligner Bowtie2 is employed to align     the sequencing reads to a reference genome (Langmead and Salzberg     2012). In cases where the input files are large, such as those     obtained from ATAC-Seq experiments, the pipeline optimizes alignment     speed by splitting the files into smaller chunks and performing     parallel alignments.</li> <li>PCR Duplicate Removal: The pipelines incorporate the Picard mark     duplicates function (Broad Institute, n.d.) and Samtools (H. Li et     al. 2009) to estimate and remove PCR duplicates. By employing merged     alignments, the duplicate reads can be efficiently identified and     eliminated, ensuring accurate downstream analysis.</li> <li>ATAC-Seq-specific Analysis: In the case of ATAC-Seq data, the     pipeline performs additional steps. It identifies accessible     chromatin regions by estimating the Tn5 transposase cut sites. This     estimation involves positioning on the 9th base upstream of the 5'     read end and extending by 29 bases downstream. This extension     process is based on studies (Donnard et al. 2018; Buenrostro et     al. 2013) that have shown it to more accurately reflect the exact     positions accessible to the transposase. Subsequently, peaks are     called using MACS2 (Zhang et al. 2008) in both the ChIP-Seq and     ATAC-Seq pipelines.</li> <li>Consensus Peak Calling and Quantification: When processing multiple     samples together, the ATAC-Seq and ChIP-Seq pipelines offer the     option of generating consensus peak calls. This is achieved by     merging all peaks individually called in each sample using Bedtools     (Quinlan and Hall 2010). Furthermore, the pipelines quantify the     number of reads in each peak location using Bedtools' coverage     function, facilitating comprehensive analysis of the data.</li> <li>Data Analysis: As a result, both the ATAC-Seq and ChIP-Seq pipelines     generate a matrix containing count values for each peak region and     sample. This matrix can be directly uploaded to the embedded version     of DEBrowser (Kucukural et al. 2019) for performing differential     analysis. Alternatively, the matrix can be downloaded for further     analysis using other tools or methods.</li> </ol>"},{"location":"ViaFoundry/pipeline_example/#how-to-cite-us","title":"How To Cite Us","text":"<p>If you use Via Foundry (formerly DolphinNext) in your research, please cite:</p> <p>Yukselen, O., Turkyilmaz, O., Ozturk, A.R. et al. DolphinNext: a distributed data processing platform for high throughput genomics. BMC Genomics 21, 310 (2020). https://doi.org/10.1186/s12864-020-6714-x</p>"},{"location":"ViaFoundry/pipeline_example/#support","title":"Support","text":"<p>For any questions or help, please reach out to support@viascientific.com with your name and question.</p>"},{"location":"ViaFoundry/profile/","title":"Profile Guide","text":"<p>In this guide, you'll discover all the available options you can explore on your Via Foundry Profile page.</p>"},{"location":"ViaFoundry/profile/#profile-page","title":"Profile Page","text":"<p>After logging in, simply click on the \"Profile\" tab located at the top-right corner of your screen. You'll see a number of different tabs on your profile page that you can click through and explore.</p> <p></p> <p>The platform offers several options for creating connection profiles and managing your credentials.</p> <ul> <li>First up is the Run Environments tab, which is your main hub for     creating connection profiles.</li> <li>Next, you can use the Groups tab to create a group and add     members to it, allowing you to share your runs or pipelines with     others.</li> <li>To manage your SSH keys, you'll need to head over to the Run     Environments tab, where you can create new keys or enter existing     SSH key pairs in the <code>Edit</code> section to establish connections with     hosts.</li> <li>You can also add your Amazon Keys or Google Keys in order to     execute your runs in the cloud.</li> <li>Under the Repositories tab (formerly called GitHub), you can     enter your security credentials to push your pipeline information to     your Github or Bitbuckets account.</li> <li>If you're not using Google sign-in, you can change your password     within the Change Password section.</li> <li>Lastly, in the Notification tab, you can opt into receiving     emails about completed or failed runs.</li> </ul> <p>It's important to note that before creating a run environment, you'll need to create SSH keys in the Run Environments tab. And if you plan on executing runs in the cloud, you'll need to add your Amazon or Google keys as well.</p>"},{"location":"ViaFoundry/profile/#ssh-keys","title":"SSH Keys","text":"<p>To create or enter existing SSH key pairs, navigate to the SSH Keys tab and click on the <code>Add SSH Key</code> button in the top right corner.</p> <p>Next, you'll need to choose between two methods:</p> <ul> <li>A. Use your own keys: If you choose this option, you'll need to     provide your private and public key pairs. You can find these keys     on your computer at the default location: '~/.ssh/id_rsa 'for the     private key and '~/.ssh/id_rsa.pub' for the public key. Simply     copy and paste these keys into the appropriate fields in your     browser. If these files don't exist or you want to create new ones,     check out this      link     for guidance.</li> <li>B. Create new keys: To generate a new pair of SSH keys, simply     click the \"Generate Keys\" button.</li> </ul> <p>After you've saved your key, your information will be encrypted and kept secure. To establish a connection, you'll need to add your public key to the '~/.ssh/authorized_keys' file on the host machine. For help with this step, feel free to contact us at support@viascientific.com.</p>"},{"location":"ViaFoundry/profile/#amazon-keys","title":"Amazon Keys","text":"<p>To enter your AWS security credentials (access key, secret key, and default region), head over to the Amazon Keys tab and click on the <code>Add Amazon Key</code> button. Rest assured that your information will be encrypted and kept secure, and only you will have full access to view and modify your key information.</p> <p>Note: Once you've saved your key, it won't be visible for security purposes. However, you can always overwrite it with a new key or delete it if needed.</p>"},{"location":"ViaFoundry/profile/#google-keys","title":"Google Keys","text":"<p>To enter your Project ID and Service Account Key in the Google keys tab, start by clicking the <code>Add Google Key</code> button.</p> <ul> <li>For your Project ID, head over to the Google Cloud Console and     navigate to the Dashboard section. From there, check the Project     info box to find your Project ID, which should look something like     \"viafoundry-193616\".</li> <li>To input your Service Account Key, also head over to the Google     Cloud Console and navigate to APIs &amp; Services \u2192 Credentials.     From there, click on the <code>Create Credentials</code> drop-down and select     <code>Service Account Key</code>. On the following page, choose an existing     service account or create a new one if needed, then select JSON as     the \"Key Type\". Finally, click the Create button and download the     JSON file with a name of your choice (e.g., creds.json).</li> </ul> <p>Remember that, after saving your key, you won't be able to view your Service Account Key for security reasons. However, you can always overwrite it with a new key or delete it if necessary.</p>"},{"location":"ViaFoundry/profile/#groups","title":"Groups","text":"<p>In the Groups tab, you can create groups by selecting the <code>Create a Group</code> button. Once you have created a group, you can add members by clicking the <code>Options &gt; Edit Group Members</code> button. This interactive platform allows you to share your process, pipeline, or projects with your group members. To view the current members of the group, select the <code>Options &gt; View Group Members</code> button. Additionally, you have the option to delete your group by selecting the <code>Options &gt; Delete Group</code> button, or to edit its name with <code>Options &gt; Edit Group Name</code>.</p>"},{"location":"ViaFoundry/profile/#run-environments","title":"Run Environments","text":""},{"location":"ViaFoundry/profile/#software-dependencies","title":"Software Dependencies","text":"<p>In order to execute our pipelines, you have to install and validate certain software dependencies into your host machine.</p> <p>To enable proper pipeline execution, Nextflow should be installed into your host environment. Since most of our pipelines isolate their dependencies within their Docker, please install Docker or Podman into your machine by following the guidelines below. If your platform doesn't support the installation of Docker, you can still use our pipelines with just Singularity.</p> <ul> <li>Installing     Nextflow</li> <li>Installing     Docker</li> <li>Installing Singularity (Version     3)</li> </ul> <p>How to Add Software to Your $PATH Environment:</p> <ul> <li>JAVA Command (optional): If JAVA is not added to the $PATH     environment, you can run the command (<code>module load java/8.0</code>) to     manipulate your $PATH environment and gain access to JAVA.</li> <li>Nextflow Path or Command (optional): If Nextflow is not added     to the $PATH environment, you can either enter the path of the     nextflow (eg. <code>/project/bin</code>), or run the command     (<code>module load nextflow</code>) to manipulate your $PATH environment and     gain access to new software.</li> <li>Docker/Singularity Command (optional): You can run a command     (eg. <code>module load docker/1.0.0</code> or     <code>module load singularity/3.0.0</code>) to manipulate your $PATH     environment in order to gain access to new software.</li> </ul> <p>You can set general run settings by following the Run Environments section:</p> <ul> <li>Executor of Nextflow: Nextflow itself is initiated with this     method, which will be only used for running Nextflow itself.</li> <li>Executor of Nextflow Jobs: This setting will be used as the     default setting for submitted jobs by Nextflow.</li> <li>Download Directory: Used to download shared pipeline files     such as genome indexes. If your platform already has an allocated     path for such files, please enter that path. Otherwise, you can     set any path that you have permission to write. e.g.     <code>/share/viafoundry/downloads</code></li> </ul> <p>Once you complete these steps, you're now able to start using publicly available pipelines.</p> <p>This section is used for defining connection profiles by clicking on the <code>Add Environment</code> button. You can choose from three options: Host, Amazon or Google.</p> <ul> <li>Host: This option is for users who have access to High     Performance Computing (HPC) environments or personal workstations.</li> <li>Amazon: This option is for users who have an Amazon Web Services     (AWS) account or plan to create an EC2 instance to run jobs in the     cloud.</li> <li>Google: This option is for users who want to use their Google     Cloud account to run jobs in the cloud.</li> </ul>"},{"location":"ViaFoundry/profile/#a-defining-host-profiles","title":"A. Defining Host Profiles:","text":"<ul> <li> <p>Username/Hostname: To connect to a remote host, you need to     provide your username and the hostname of the remote host in the     format \"yourusername@yourhostname\". For instance, for the     username \"us2r\" and hostname \"ghpcc06.umassrc.org\", you should     enter \"us2r@ghpcc06.umassrc.org\".</p> </li> <li> <p>SSH Port (optional): By default, Via Foundry uses TCP port 22     for SSH connections. However, you can specify a different port     number if needed.</p> </li> <li> <p>SSH Keys: Via Foundry stores your SSH keys in the SSH keys tab     and uses them to authenticate your SSH connections.</p> </li> <li> <p>Run Command (optional): You can specify a command or a series of     commands to run before starting the Nextflow job. Separate multiple     commands using \"&amp;&amp;\". For example:</p> <pre><code>source /etc/bashrc &amp;&amp; module load java/1.8.0_77 &amp;&amp; module load\nsingularity/singularity-3.4.0\n</code></pre> </li> <li> <p>Nextflow Path (optional): If the Nextflow executable is not in     your $PATH, you can specify the path to the executable in this     block. For example:</p> <pre><code>/project/umw_biocore/bin\n</code></pre> </li> <li> <p>Singularity Cache Folder: Via Foundry uses a local directory to     store Singularity images downloaded from remote hosts. By default,     this directory is located in your home directory. However, if you     are using a computing cluster, you need to specify a shared     directory that is accessible from all computing nodes.</p> </li> <li> <p>Profile Variables: To facilitate the use of genome reference and     index files in your pipelines, you can specify a download directory     in which these files are stored. If multiple users are using Via     Foundry, it is recommended to use a shared path in your cluster. For     example:</p> <pre><code>params.DOWNDIR=\"/share/dolphinnext/downloads\"\n</code></pre> </li> <li> <p>Environment Variables: You can set BASH environmental variables     here. Note: don't use spaces to separate multiple variables; use     newlines instead.</p> </li> <li> <p>Executor Settings: In Via Foundry, there are four different     sections to control executor settings: the first two are defined in     Profile -&gt; Run Environment, and the remaining two are     adjusted in the Advanced tab of the run page. If you select an     executor other than \"Local\" or \"Ignite\", Via Foundry prompts you     to enter additional settings, such as the queue/partition, memory,     CPU, and time.</p> <p>1. Executor of Nextflow (navigate to Profile -&gt; Run Environments):</p> <p>This setting controls how Via Foundry initiates Nextflow. Currently, Via Foundry supports the Local, SGE, SLURM, and LSF executors to initiate Nextflow. For the SGE, SLURM, and LSF executors, Via Foundry only uses them to run Nextflow itself, so the time limit should be long enough to execute all processes in the pipeline. For local execution, DolphinNext limits the total amount of memory and CPU that can be used, so these values should be close to the maximum capacity of your computer.</p> <ul> <li>Suggested parameters for SGE/SLURM/LSF: long (queue) 8 (GB     Memory) 1 (CPU) 5000-8000 (min, Time)</li> <li>Suggested parameters for Local: 100 (GB Memory) 8 (CPU)</li> </ul> <p>2. Executor of Nextflow Jobs (navigate to Profile -&gt; Run Environments):</p> <p>This setting will be used as the default setting for submitted jobs by Nextflow if you don't set any parameters in the Advanced section of your run page.</p> <ul> <li>Suggested parameters for SGE/SLURM/LSF: short (queue) 20 (GB     Memory) 1 (CPU) 240 (min, Time)</li> <li>Suggested parameters for Local: 20 (GB Memory) 1 (CPU)</li> </ul> <p>3. Executor Settings for All Processes (in the advanced tab of run page):</p> <p>These settings will overwrite those in Executor of Nextflow Jobs and set default parameters for all Nextflow Jobs.</p> <ul> <li>Suggested parameters for SGE/SLURM/LSF: short (queue) 20 (GB     Memory) 1 (CPU) 240 (min, Time)</li> <li>Suggested parameters for Local: 20 (GB Memory) 1 (CPU)</li> </ul> <p>4. Executor Settings for Each Process (in the advanced tab of run page):</p> <p>If a particular process requires different parameters than the defaults (which are defined in the Executor Settings for All Processes or Executor of Nextflow Jobs sections), you can overwrite the general settings by clicking the checkbox of the process that you want to change. This will only affect the settings of the selected process and keep the original settings for the rest of the processes.</p> <ul> <li>Suggested parameters for SGE/SLURM/LSF: long (queue) 20 (GB     Memory) 4 (CPU) 1000-5000 (min, Time)</li> <li>Suggested parameters for Local: 20 (GB Memory) 4 (CPU)</li> </ul> <p>Note: If non-standard resources or settings are required for the executor, then you can specify these parameters by using Other Options box. For instance, to submit an SGE job with 3 CPU using parallel environments, you can enter <code>-pe orte 3</code> (to use MPI for distributed-memory machines) or <code>-pe smp 3</code> (to use OpenMP for shared-memory machines) in the Other Options box, leaving the CPU box empty. :::</p> </li> </ul>"},{"location":"ViaFoundry/profile/#b-defining-aws-batch-profiles","title":"B. Defining AWS Batch Profiles:","text":"<p>Please choose type of the run environment as \"Host\" and enter following information.</p> <ul> <li> <p>Username/Hostname: To connect to a remote host, you need to     provide your username and the hostname of the remote host in the     format \"yourusername@yourhostname\". For instance, for the     username \"us2r\" and hostname \"ghpcc06.umassrc.org\", you should     enter \"us2r@ghpcc06.umassrc.org\".</p> </li> <li> <p>SSH Port (optional): By default, Via Foundry uses TCP port 22     for SSH connections. However, you can specify a different port     number if needed.</p> </li> <li> <p>SSH Keys: Via Foundry stores your SSH keys in the SSH keys tab     and uses them to authenticate your SSH connections.</p> </li> <li> <p>Run Command (optional): You can specify a command or a series of     commands to run before starting the Nextflow job. Separate multiple     commands using \"&amp;&amp;\". For example:</p> <pre><code>source /etc/bashrc &amp;&amp; module load java/1.8.0_77 &amp;&amp; module load\nsingularity/singularity-3.4.0\n</code></pre> </li> <li> <p>Nextflow Path (optional): If the Nextflow executable is not in     your $PATH, you can specify the path to the executable in this     block. For example:</p> <pre><code>/project/umw_biocore/bin\n</code></pre> </li> <li> <p>Singularity Cache Folder: Via Foundry uses a local directory to     store Singularity images downloaded from remote hosts. By default,     this directory is located in your home directory. However, if you     are using a computing cluster, you need to specify a shared     directory that is accessible from all computing nodes.</p> </li> <li> <p>Profile Variables: You can set commonly used pipeline variables     here. For instance,<code>params.DOWNDIR</code> is used in most of our public     pipelines to save all genome related files (fasta, index etc.), so     you can set this variable like this:     <code>params.DOWNDIR = \"/share/dnext_data\"</code> Also, you can enter multiple     variables by separating them with newlines.</p> </li> <li> <p>Environment Variables: You can set BASH environmental variables     here. Note: don't use spaces to separate multiple variables; use     newlines instead.</p> </li> <li> <p>Executor of Nextflow: Please select the <code>Local</code> Nextflow     executor.</p> </li> <li> <p>Executor Settings for Nextflow: Please enter 10GB in the     Memory field and 1 in the CPU field.</p> </li> <li> <p>Executor of Nextflow Jobs: Please select <code>AWS Batch</code> for     Nextflow jobs.</p> </li> <li> <p>Queue, Memory, CPU, and other options: Please enter the queue     name and set the default memory and CPU you'll allocate for each     job (e.g. 10GB memory and 1CPU). These settings can be adjusted in     the run page.</p> </li> <li> <p>Amazon Keys: AWS credentials that are saved in the Amazon     Keys tab will allow you to submit jobs to AWS Batch.</p> </li> <li> <p>Default Working Directory: Default directory in the host machine     where runs will be executed. (eg. <code>/data/dnext</code>)</p> </li> <li> <p>Default Bucket Location for Publishing: Default bucket location     where dolphinnext reports will be published. (e.g.     <code>s3://bucket/dnext</code>)</p> </li> </ul>"},{"location":"ViaFoundry/profile/#c-defining-non-batch-amazon-web-services-profiles","title":"C. Defining Non-Batch Amazon Web Services Profiles:","text":"<p>SSH Keys: These are saved in the SSH Keys tab and will be used when connecting to a host. SSH keys are a secure way to authenticate and encrypt connections between servers. It's recommended to generate a new key pair for each instance you plan to connect to. * Amazon Keys: These AWS credentials are saved in the Amazon Keys tab and allow you to start/stop Amazon EC2 instances. These credentials consist of an access key and a secret access key. * Instance Type: This refers to the type of _Amazon EC2 instance that you will use. Instance types comprise varying combinations of CPU, memory, storage, and networking capacity. For example, \"m3.xlarge\" is an instance type that provides a balance of CPU and memory resources. * Image ID: This is the virtual machine ID (VM ID) that you will use to launch the instance. The image ID is specific to the region and operating system that you are using. For example, \"ami-032a33ebe57465518\" is a sample image ID for an Amazon Machine Image (AMI) that is based on the Ubuntu operating system.</p> <p>If you want to create your own image, please install the following programs:</p> <ul> <li>Singularity</li> <li>Docker engine (version 1.11 or         higher)</li> <li>Apache Ignite with Cloud-init package</li> <li>Nextflow</li> <li>AWS         CLI</li> </ul> <ul> <li> <p>Subnet ID/Security Group/Shared Storage ID/Shared Storage Mount:</p> <p>The filesystem needs to be created at https://console.aws.amazon.com/efs/, and this information will be obtained upon the creation of a shared file system.</p> <ul> <li>Subnet ID: Identifier of the VPC subnet to be applied,         e.g., subnet-05222a43.</li> <li>Security Group: Identifier of the security group to be         applied, e.g., sg-df72b9ba, which is used by default.</li> <li>Shared Storage ID: Identifier of the shared file system         instance, e.g., fs-1803efd1.</li> <li>Shared Storage Mount: Mount path of the shared file         system, e.g., /mnt/efs.</li> </ul> <p>Please make sure the following criteria are satisfied:</p> <ol> <li>The image used must have the directory to mount this         storage.</li> <li>The output directory must be under this mount location.</li> <li>The storage system must be created in the selected region,         and necessary rights need to be given in the console.</li> <li>The EC2FullAccess and S3FullAccess permissions have been         added.</li> </ol> <p>Warning: Both the EFS and images should be located in the same location.</p> </li> <li> <p>Default Working Directory: This is the default directory in the     host machine where runs will be executed. It is an optional     parameter for AWS. For example, you can set it to \"/data/dnext\".</p> </li> <li> <p>Default Bucket Location for Publishing: This is the default     bucket location where Via Foundry reports will be published. It is     also an optional parameter for AWS. For example, you can set it to     <code>s3://bucket/dnext</code>.</p> </li> <li> <p>Run Command (optional): You may specify a command or multiple     commands to be run before the Nextflow job starts. Separate multiple     commands with the &amp;&amp; sign. For example, you could use the following     command to load modules before running the job:     <code>source /etc/bashrc &amp;&amp; module load java/1.8.0_31 &amp;&amp; module load bowtie2/2.3.2</code>.</p> </li> <li> <p>Nextflow Path (optional): If the Nextflow path is not added to     the $PATH environment variable, you can define the path in this     block. For example, you could set it to <code>/project/umw_biocore/bin</code>.</p> </li> <li> <p>Singularity Cache Folder: This is the directory where remote     Singularity images are stored. By default, the home directory is     used. Note that when using a computing cluster, it must be a shared     folder that is accessible from all computing nodes.</p> </li> <li> <p>Profile Variables: You can set commonly used pipeline variables     here. For instance,<code>params.DOWNDIR</code> is used in most of our public     pipelines to save all genome related files (fasta, index etc.), so     you can set this variable like this:     <code>params.DOWNDIR = \"/share/dnext_data\"</code> You can also enter multiple     variables by separating them with newlines.</p> </li> <li> <p>Executor of Nextflow/Executor of Nextflow Jobs: Amazon instances     are automatically configured to use the Ignite executors. As such,     when defining an Amazon profile, you should select <code>Local</code> for     Executor of Nextflow and <code>Ignite</code> for Executor of Nextflow     Jobs.</p> </li> </ul>"},{"location":"ViaFoundry/profile/#d-defining-google-profiles","title":"D. Defining Google Profiles:","text":"<ul> <li> <p>SSH Keys: are saved in SSH keys tab and will be used while     connecting to host.</p> </li> <li> <p>Google Keys: Google credentials that are saved in Google keys     tab and will allow to start/stop Google Cloud instances.</p> </li> <li> <p>Zone: The Google zone where the computation is executed.(eg.     us-east1-b)</p> </li> <li> <p>Instance Type: Google Cloud machine     types that     comprise varying combinations of CPU, memory, storage, and     networking capacity (eg. <code>n1-standard-4</code>).</p> </li> <li> <p>Image ID: Virtual machine ID (eg.     <code>dolphinnext-193616/global/images/dolphinnext-images-v1</code>).</p> <p>If you want to create your own image, please install following programs:</p> <ul> <li>Singularity</li> <li>Docker engine (version 1.11 or         higher)</li> <li>Apache Ignite with Cloud-init package</li> <li>Nextflow</li> <li>gcloud</li> </ul> </li> <li> <p>Default Working Directory: This is the default directory in the     host machine where runs will be executed. It is mandatory for Google     Cloud profiles. (e.g., /data/dnext)</p> </li> <li> <p>Default Bucket Location for Publishing: This is the default     bucket location where Via Foundry reports will be published. It is     mandatory for Google Cloud profiles, and you can always edit this     path in the run page. For example, you could set it to     <code>gs://bucket/dnext</code>.</p> </li> <li> <p>Run Command (optional): You may specify a command or multiple     commands to be run before the Nextflow job starts. Separate multiple     commands with the &amp;&amp; sign. For example, you could use the following     command to load modules before running the job:     <code>source /etc/bashrc &amp;&amp; module load java/1.8.0_31 &amp;&amp; module load bowtie2/2.3.2</code>.</p> </li> <li> <p>Nextflow Path (optional): If the Nextflow path is not added to     the $PATH environment variable, you can define the path in this     block. For example, you could set it to <code>/project/umw_biocore/bin</code>.</p> </li> <li> <p>Singularity Cache Folder: This is the directory where remote     Singularity images are stored. By default, the home directory is     used. Note that when using a computing cluster, it must be a shared     folder that is accessible from all computing nodes.</p> </li> <li> <p>Profile Variables: You can set commonly used pipeline variables     here. For instance,<code>params.DOWNDIR</code> is used in most of our public     pipelines to save all genome related files (fasta, index etc.), so     you can set this variable like this:     <code>params.DOWNDIR = \"/share/dnext_data\"</code> You can also enter multiple     variables by separating them with newlines.</p> </li> <li> <p>Executor of Nextflow/Executor of Nextflow Jobs: Google instances     are automatically configured to use the Ignite executors. As such,     when defining a Google profile, you can select <code>Local</code> for     Executor of Nextflow and <code>Ignite</code> for Executor of Nextflow     Jobs.</p> </li> </ul>"},{"location":"ViaFoundry/profile/#github-connection","title":"GitHub Connection","text":"<p>You can enter your GitHub or Bitbucket security credentials (Username, E-mail, Password) by clicking on the <code>Add Account</code> button in the Repositories tab. Your information will be encrypted and kept secure. By adding a Github or Bitbucket account, you'll be able to push your pipeline information into a public account, where you can then share it with others.</p>"},{"location":"ViaFoundry/profile/#change-password","title":"Change Password","text":"<p>If you're not using a Google sign-in, you can change your Via Foundry password by using this section.</p>"},{"location":"ViaFoundry/profile/#support","title":"Support","text":"<p>For any questions or help, please reach out to support@viascientific.com with your name and question.</p>"},{"location":"ViaFoundry/project/","title":"Project Guide","text":"<p>This guide will walk you through creating a project using the Via Foundry platform, and how to insert pipelines and files into it.</p>"},{"location":"ViaFoundry/project/#creating-projects-and-adding-pipelines","title":"Creating Projects and Adding Pipelines","text":"<p>Projects are platforms to categorize all of your runs and files. To run a pipeline, you must add it into your project. There are two ways to create a new project and add pipelines to it:</p> <ul> <li>A.  First, click the \"Projects\" button in the top of the screen.           From the dropdown menu, you can create a new project by           clicking <code>Add a New Project</code>. After saving the name of the           project, it will be added to your Projects table, which is           accessible from the dropdown menu, as shown in the image           below:</li> </ul> <p></p> <p>Note: You can always edit or remove your projects by clicking <code>View All Projects</code> button or clicking on the project   name from the dropdown menu, navigating to the <code>Settings</code> tab, and   clicking the <code>Edit</code> or <code>Delete Project</code> icons.</p> <p>Now you are able to enter the project page by clicking the name of the project from the <code>Projects</code> dropdown menu. You will notice five tabs in the project page:</p> <ul> <li>Dashboard: Your project's homepage. The dashboard contains the <code>Description</code> box, where you can write down information about the project; and the <code>Analysis</code> section, which will contain reports on the project and its runs.</li> <li>Data Collections: The project files can be organized in this section. You can create collections on the run page and reorganize them here. To add data, simply click the \"Add Collection\" button.</li> <li>Pipelines: To make the desired pipeline(s) available for your project, click on the \"Add Pipeline\" button. From the provided list, select the pipelines you want to include. Once selected, click the run button to navigate to the run page. If you wish to create a custom pipeline, click on the \"Create Pipeline\" button.</li> <li>Runs: Table containing information about all the runs         conducted in your current project (see image below). You can         enter a specific run's page by clicking on the name of the          run.</li> <li> <p>Settings: Information about your project: name, creator,         and date/time created. From this tab, you can edit or delete a         given project, as mentioned above.     </p> </li> <li> <p>B.  You can also create a project by clicking the <code>Pipelines</code>           button on the top left of the page. Select the pipeline you           want to run by clicking on it. At the top right of the           pipeline page, you'll see a <code>Run</code> button; press this to           initiate a run.</p> </li> </ul> <p></p> <p>The <code>Run</code> button opens a new window where you can create a new project   by clicking <code>Create a Project</code>. After entering and saving the project   name, it will be added to your project list. From here, you can select   your project by clicking on it, as shown in the image below.</p> <p></p> <p>You can proceed by entering the run name, which will subsequently be   added to your project's run list. Clicking <code>Save Run</code> will redirect   you to the \"Run Page\", where you can initiate your run.</p>"},{"location":"ViaFoundry/project/#support","title":"Support","text":"<p>For any questions or help, please reach out to support@viascientific.com with your name and question.</p>"},{"location":"ViaFoundry/quick/","title":"Quick Start Guide","text":""},{"location":"ViaFoundry/quick/#signing-up","title":"Signing Up","text":"<p>This guide will walk you through how to start using Via Foundry (formerly DolphinNext) pipelines. First off, you need to navigate to the Via Foundry web page at https://www.viafoundry.com and click the <code>Log in</code> button. You will be asked to enter your institute's log-in information. If you don't have an account, please let us know about it  support@viascientific.com. We will set an account for you.</p> <p></p>"},{"location":"ViaFoundry/quick/#run-environments","title":"Run Environments","text":"<p>To access your run environment, simply click on the Profile icon located at the top right corner and navigate to the Run Environment tab. In most cases, we automatically set up the run environment for you. However, if you require additional information on setting up and customizing your profile, please refer to our comprehensive Profile Guide.</p>"},{"location":"ViaFoundry/quick/#running-pipelines","title":"Running Pipelines","text":"<ol> <li> <p>The easiest way to run a pipeline is from the main page, by clicking     the <code>Pipelines</code> button at the top left of the screen. From here, you     can investigate publicly available pipelines as shown below and     select the pipeline you want to run by clicking on it.</p> <p></p> </li> <li> <p>Once the pipeline is loaded, you will notice a <code>Run</code> button at the     right top of the page.</p> <p></p> </li> <li> <p>Pressing this button opens a new window, where you can create a new     project by clicking <code>Create a Project</code>. After you enter and save the     name of the project, it will be added to your project list. Now you     can select your project by clicking on it, as shown in the figure     below.</p> <p></p> </li> <li> <p>After clicking <code>Select Project</code>, you may proceed with entering your     desired run name, which will be added to your project's run list.     Clicking <code>Save Run</code> will redirect you to the \"Run Page\".</p> </li> <li> <p>At first, in the header of the run page, you will see an orange \"Waiting\" button. To start a run, you need to enter/select the following:</p> <p></p> <p>A.  Run Environment: The environment, discussed in the Profile page, within which you'd like to conduct your run.</p> <p></p> <p>B. Work Directory: The work directory refers to the complete path of the directory from which the execution of Nextflow runs will take place. The path may be automatically filled in if a default value is provided in your run environment.</p> <p></p> <p>C. Inputs: In this section, you are required to enter various values and files that define the data to be processed and the corresponding processing instructions. For additional information, please check the Adding Files section.</p> <p></p> </li> <li> <p>Once all requirements are satisfied, the <code>Waiting</code> button will turn     into a green <code>Run</code> button as shown below. You can initiate your run     by clicking the <code>Run</code> button. Please go through the Run     Guide for detailed explanation about each module is used.</p> <p></p> </li> </ol>"},{"location":"ViaFoundry/quick/#adding-files","title":"Adding Files","text":""},{"location":"ViaFoundry/quick/#remote-files","title":"Remote Files","text":"<p>You can reach your remote files by entering:</p> <ul> <li>Full path of a directory: e.g.       <code>/share/data/umw_biocore/genome_data/mousetest/mm10/gz</code></li> <li>Web link: e.g.       <code>https://web.dolphinnext.com/umw_biocore/dnext_data/tutorial/fastq_data/pair</code></li> <li>Amazon (S3) Bucket: e.g. <code>s3://viafoundry/fastq</code></li> <li>Google (GS) Bucket: e.g. <code>gs://viafoundry/fastq</code></li> </ul>"},{"location":"ViaFoundry/quick/#geo-files","title":"Geo Files","text":"<p>If you want to download and use NCBI (GEO data) in the pipeline, you can simply use the <code>GEO Files</code> tab. Here are the few examples for GEO ID: <code>GSM1331276</code>, <code>GSE55190</code>, <code>SRR10095965</code></p> <p></p>"},{"location":"ViaFoundry/quick/#how-to-cite-us","title":"How To Cite Us","text":"<p>If you use Via Foundry (formerly DolphinNext) in your research, please cite:</p> <p>Yukselen, O., Turkyilmaz, O., Ozturk, A.R. et al. DolphinNext: a distributed data processing platform for high throughput genomics. BMC Genomics 21, 310 (2020). https://doi.org/10.1186/s12864-020-6714-x</p>"},{"location":"ViaFoundry/quick/#support","title":"Support","text":"<p>For any questions or help, please reach out to support@viascientific.com with your name and question.</p>"},{"location":"ViaFoundry/run/","title":"Run Guide","text":"<p>In the previous tutorial (Project Guide), we went through the process of creating a project within the Via Foundry (formerly DolphinNext) platform and adding pipelines to it. In this guide, we will look through all the relevant run settings needed to initiate a new run.</p>"},{"location":"ViaFoundry/run/#brief-refresher","title":"Brief Refresher","text":"<p>To access a run page, navigate to the project the run is housed within by clicking on the appropriate project name in the <code>Project</code> dropdown menu. On the <code>Dashboard</code> page, under the <code>Analysis</code> section, click the name of your run.</p>"},{"location":"ViaFoundry/run/#basics","title":"Basics","text":"<p>On the run page's header, you can see the names of the current project, pipeline being used, and run in progress. Ensure that you're in the right project and running the correct pipeline before proceeding.</p> <p></p> <p>As you can see, <code>Save Run</code>, <code>Download Pipeline</code>, and <code>Delete Run</code> icons are conveniently placed next to the information mentioned above in the run page's header. Additionally, you can find <code>Delete Run</code>, <code>Duplicate Run</code>, and <code>Move Run</code> options by clicking on the three dots next to the status indicator.</p>"},{"location":"ViaFoundry/run/#run-settings-and-status","title":"Run Settings and Status","text":"<p>The status of your current run is displayed at the far right of the run page's header. Initially, you'll see an orange <code>Waiting</code> button. In order to initiate a run, the following data need to be entered:</p> <ol> <li>Run Environment: The environment, discussed in the      profile page, within which you'd like to conduct      your run.</li> <li>Work Directory: Full path of the directory where Nextflow runs      will be executed. (e.g. <code>/home/newuser/workdir</code>)</li> <li>Inputs: Various values and files, specifying which data      will be processed and how (i.e. whether single-end vs. paired-end      data are being used), need to be entered in the Run Settings      page. For additional information, please check the Adding Files       section.</li> </ol> <p></p> <p>All possible status messages are listed here:</p> Status Meaning Waiting Waiting for inputs, output directory and selection of active run environment Ready Ready to initiate run Connecting Sending SSH queries to selected host system Initializing Job is submitted, waiting for run execution Running Nextflow has executed and is running the jobs. Completed The job is completed. Run Error Error occurred before submitting the jobs or while executing the jobs. Terminated User terminated the run by using the <code>Terminate Run</code> button."},{"location":"ViaFoundry/run/#advanced-options","title":"Advanced Options","text":"<ul> <li> <p>Run Sharing (Permissions to View): By default, all runs are only visible to their owners. However, you have the option to share your run with a specific group that you have created in the profile's \"Groups\" tab. To do this, choose \"Only my group\" and select the name of the desired group. Members of that group will then be able to view the run on their run status page.</p> <p>Alternatively, you can set the permissions to \"Everyone\". With this setting, the run will only be visible to users who know the specific run link. The selected run will not appear on their run status page, but they will be able to access it if they have the link.</p> </li> <li> <p>Publish Directory: The Work Directory also serves as the default     directory to which output files are sent for Via Foundry runs. If     you want to change the path to a different directory, just enter the     full path of your desired Publish Directory in this box. Local paths     (e.g. <code>/home/user/test</code>), Amazon S3 paths (e.g.     <code>s3://yourbucket/test</code>) or Google Storage paths (e.g.     <code>gs://yourbucket/test</code>) are all accepted.</p> </li> <li> <p>Run Container: During the pipeline creation process, we specified the containers to be used for each process. Consequently, when you select the run environment, the corresponding run container (either Docker or Singularity) checkbox will be automatically selected, and the defined container will be populated in the image field.</p> <ul> <li> <p>A. Use Docker Image: </p> <ol> <li> <p>Image: Docker image name. Example:</p> <p>viascientific/rnaseq:4.0</p> </li> <li> <p>RunOptions (optional): Foundry has the ability to autodetect all the paths used and automounts all the required files to the container before the run starts. Moreover, you have the flexibility to enter any command line arguments supported by the Docker run command. Please click this Docker link for details on how you can configure this section.</p> </li> </ol> </li> <li> <p>Use Singularity Image: Instead of Docker, you can activate a Singularity image if you wish by clicking the <code>Use Singularity Image</code> checkbox and entering the relevant information, expounded upon below. In order to use a Singularity image, you must first install Singularity.</p> <ol> <li> <p>Image: Path to your desired Singularity image. For example:</p> <p><code>docker://viascientific/rnaseq:4.0</code></p> <p><code>shub://UMMS-biocore/singularitysc</code></p> <p><code>/project/umw_biocore/singularity/UMMS-Biocore-singularity-master.simg</code></p> </li> <li> <p>RunOptions (optional): Foundry automatically detects and mounts all the necessary files to the container by detecting the used paths. When using Singularity, you have the option to enter command line options supported by the Singularity exec command. One example of such an option is --bind, which allows you to mount directories. For more information about the command line arguments supported by Singularity, please refer to this link.</p> <p><code>--bind /project:/project --bind /nl:/nl</code></p> </li> </ol> </li> </ul> </li> <li> <p>Executor Settings: A series of parameters governing the     execution of your run, including what packages to run and how much     processing power to allocate to each package.</p> <p>1. Executor Settings for Nextflow: (navigate to Profile \u2192 Run Environments \u2192 Edit Run Environment): Here, you can specify the system on which Nextflow is initiated. Via Foundry currently supports various executors for running Nextflow itself, including Local, SGE, SLURM, and LSF. These executors are exclusively used for running Nextflow.</p> <p>Suggested parameters for the executor settings are as follows: long, 8GB memory, 1 CPU, and a time range of 5000-8000 minutes.</p> <p>2. Executor of Nextflow Jobs: (navigate to Profile --&gt; Run   Environments --  Edit Run Environment) This setting will be   used if you don't manually set any parameters in the Advanced   section of your run page. If any option other than Local is   selected, you'll be prompted to input values for <code>Queue</code>,   <code>Memory(GB)</code>, <code>CPU</code> and <code>Time(min.)</code>. These parameters can be adjusted according to your needs. </p> <p>Suggested parameters for this configuration are as follows: short, 20GB memory, 1 CPU, and 240 minutes of execution time.</p> <p></p> <p>3. Executor Settings for All Processes (in <code>Advanced</code> tab   of run page): This setting will override the parameters specified in the <code>Executor of Nextflow Jobs</code> section. It allows you to define the executor settings for all processes in your run.</p> <p>Suggested parameters for this configuration are as follows: short, 20GB memory, 1 CPU, and 240 minutes of execution time.</p> <p>4. Executor Settings for Each Process (in <code>Advanced</code> tab   of run page): If a particular process needs special parameters   other than Executor settings for all processes, you can   override the default parameters by clicking on the checkbox   corresponding to the process that you want to change. This will   only affect the settings of the selected process while retaining   the original settings for all other processes. Suggested   parameters: long 20GB 4CPU 1000-5000min</p> </li> <li> <p>Delete intermediate files after run: By default, Via Foundry     deletes any intermediate files created during a run, only retaining     the necessary files in report folder. This     setting is aimed at minimizing the storage required for a project,     but you can uncheck the box to keep all intermediate files.</p> </li> </ul>"},{"location":"ViaFoundry/run/#workflow","title":"Workflow","text":"<p>To provide a visualization of the current run's architecture, the selected pipeline and its modules are showed on this page. To see more information about the pipeline's settings, click the Go to Pipeline link at the top of this page.</p>"},{"location":"ViaFoundry/run/#run-logs","title":"Run Logs","text":"<p>This section keeps track of each run. You can monitor each stage of the run both before and after Nextflow execution, as shown here:</p> <p></p> <p>You can view various log files, such as timeline.html, dag.html, trace.txt, .nextflow.log, nextflow.nf, nextflow.config, as shown here:</p> <ul> <li>timeline.html:</li> </ul> <p></p> <ul> <li>dag.html:</li> </ul> <p></p> <ul> <li>trace.txt:</li> </ul> <p></p> <ul> <li>.nextflow.log:</li> </ul> <p></p> <ul> <li>nextflow.nf:</li> </ul> <p></p> <ul> <li>nextflow.config:</li> </ul> <p></p> <p>If an error occurred at any point during the run, a detailed explanation about the error will be displayed here, and the status of the run will change to <code>Run Error</code>.</p> <p></p>"},{"location":"ViaFoundry/run/#report","title":"Report","text":"<p>This tab will appear in the run page upon run initialization. You can view the output files in various modules such as R-Markdown, Datatables, Highcharts, HTML or PDF Viewer. For reference, check the example Report section of an RNA-Seq pipeline at below.</p> <p></p> <p>Each report row corresponds to an output parameter in the pipeline's workflow, and you can easily see a row's content by clicking on it. All these sections have <code>Download</code>, <code>Full Screen</code>, and <code>Open in New Window</code> icons to help you best analyze each report.</p> <p>Note: If you want to integrate your own visualization tool into Via Foundry, please let us know about it at support@viascientific.com, and we'd be happy to add it for you.</p>"},{"location":"ViaFoundry/run/#-shiny-app-debrowser-","title":"-   Shiny App - DEBrowser -","text":"<p>DEBrowser is an R library which provides an easy way to perform and visualize DE (Differential Expression) analysis. This module takes count matrices as input and allows interactive exploration of the resulting data. You can find their documentation here.</p> <p></p>"},{"location":"ViaFoundry/run/#-r-studio-r-markdown-","title":"-   R-Studio - R-Markdown -","text":"<p>The R-Studio launcher facilitates interactive analysis of the data generated from a run. We have prepared a set of R-Markdown reports that provide access to your report in HTML or PDF format immediately after the run is completed.</p> <p>For instance, the code below performs differential expression analysis for each comparison listed in the compare file. It generates volcano and MA plots for differentially expressed genes in each comparison:</p> <p></p>"},{"location":"ViaFoundry/run/#-jupyter-notebook-","title":"-   Jupyter Notebook -","text":"<p>The Jupyter Notebook app, due to its interactive and flexible nature, it allows bioinformatics researchers to combine code, visualizations, and explanatory text in a single document. Bioinformaticians can write and execute code snippets in real-time, visualize data using various plotting libraries, and document their analyses step-by-step.</p> <p></p>"},{"location":"ViaFoundry/run/#-shiny-app-gsea-explorer-","title":"-   Shiny App - GSEA Explorer -","text":"<p>GSEA Explorer is an R library that offers a convenient method for conducting and visualizing Gene Set Enrichment Analysis (GSEA). GSEA aims to assess whether a specific gene set or pathway is enriched in gene expression data, indicating its potential biological significance in the studied condition. The GSEA Explorer application can be accessed after executing Foundry's complete RNA-sequencing pipeline or the standalone Differential Expression module. By leveraging GSEA Explorer, researchers can gain valuable insights into the functional implications of gene sets and pathways, aiding in the interpretation of RNA-seq results and facilitating a deeper understanding of biological mechanisms.</p> <p></p>"},{"location":"ViaFoundry/run/#-shiny-app-network-explorer-","title":"-   Shiny App - Network Explorer -","text":"<p>The Network Explorer allows bioinformaticians to explore and analyze these complex networks, helping them uncover hidden patterns, identify key players, and understand the underlying biological mechanisms. The Network Explorer application can be launched after running Foundry's full RNA-sequencing pipeline or the stand-alone Differential Expression module.</p> <p></p>"},{"location":"ViaFoundry/run/#-datatables-","title":"-   Datatables -","text":"<p>This module, powered by Datatables, allows you to view, sort, and search the table's content. The following two examples depict alignment and RSEM summaries within Datatables.</p> <ul> <li>Alignment Summary:</li> </ul> <p></p> <ul> <li>RSEM Summary:</li> </ul> <p></p> <p>You can fit the entire table in your screen by clicking the <code>Full screen</code> icon at the top of the module.</p>"},{"location":"ViaFoundry/run/#-htmlpdf-viewer-","title":"-   HTML/PDF Viewer -","text":"<p>You can easily embed HTML/PDF content in our Report section by using HTML/PDF Viewer. Reference this image, which shows MultiQC output, for an example:</p> <p></p>"},{"location":"ViaFoundry/run/#support","title":"Support","text":"<p>For any questions or help, please reach out to support@viascientific.com with your name and question.</p>"}]}